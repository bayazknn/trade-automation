{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5decc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add user_data directory to path for crypto_analysis package\n",
    "user_data_path = Path.cwd().parent\n",
    "data_dir = user_data_path / \"data\" / \"binance\"\n",
    "sys.path.insert(0, str(user_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f81acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crypto_analysis import (\n",
    "    DatasetBuilder,\n",
    "    LSTMMetaheuristicOptimizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f00b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating target signals for DOGE...\n",
      "Initial index (0): entry=140, exit=140\n",
      "Found optimal index (0): entry=140, exit=140\n",
      "Processing 57 indicators with 15 workers...\n",
      "  [RSI] Grid search optimization...\n",
      "  [MACD] Grid search optimization...\n",
      "  [STOCH] Grid search optimization...\n",
      "  [STOCHRSI] Grid search optimization...\n",
      "  [CCI] Grid search optimization...\n",
      "  [MFI] Grid search optimization...\n",
      "  [WILLR] Grid search optimization...\n",
      "  [CMO] Grid search optimization...\n",
      "  [ADX] Grid search optimization...\n",
      "  [MOM] Grid search optimization...\n",
      "  [ROC] Grid search optimization...\n",
      "  [TRIX] Grid search optimization...\n",
      "  [ULTOSC] Grid search optimization...\n",
      "  [APO] Grid search optimization...\n",
      "  [PPO] Grid search optimization...\n",
      "  [TRIX] Grid search done - score: 16\n",
      "  [BOP] Grid search optimization...\n",
      "Completed 1/57: TRIX\n",
      "  [BOP] Grid search done - score: 0\n",
      "  [AROON] Grid search optimization...\n",
      "Completed 2/57: BOP\n",
      "  [MOM] Grid search done - score: 48\n",
      "  [AROONOSC] Grid search optimization...\n",
      "Completed 3/57: MOM\n",
      "  [ROC] Grid search done - score: 48\n",
      "  [ADXR] Grid search optimization...\n",
      "Completed 4/57: ROC\n",
      "  [AROON] Grid search done - score: 29\n",
      "  [DX] Grid search optimization...\n",
      "Completed 5/57: AROON\n",
      "  [AROONOSC] Grid search done - score: 29\n",
      "  [MACDEXT] Grid search optimization...\n",
      "Completed 6/57: AROONOSC\n",
      "  [APO] Grid search done - score: 38\n",
      "  [MACDFIX] Grid search optimization...\n",
      "Completed 7/57: APO\n",
      "  [MACDFIX] Grid search done - score: 19\n",
      "  [MINUS_DI] Grid search optimization...\n",
      "Completed 8/57: MACDFIX\n",
      "  [PPO] Grid search done - score: 38\n",
      "  [MINUS_DM] Grid search optimization...\n",
      "Completed 9/57: PPO\n",
      "  [MINUS_DM] Grid search done - score: 75\n",
      "  [PLUS_DI] Grid search optimization...\n",
      "Completed 10/57: MINUS_DM\n",
      "  [ULTOSC] Grid search done - score: 87\n",
      "  [PLUS_DM] Grid search optimization...\n",
      "Completed 11/57: ULTOSC\n",
      "  [PLUS_DM] Grid search done - score: 129\n",
      "  [ROCP] Grid search optimization...\n",
      "Completed 12/57: PLUS_DM\n",
      "  [ROCP] Grid search done - score: 48\n",
      "  [ROCR] Grid search optimization...\n",
      "Completed 13/57: ROCP\n",
      "  [MACD] Grid search done - score: 35\n",
      "  [ROCR100] Grid search optimization...\n",
      "Completed 14/57: MACD\n",
      "  [MACDEXT] Grid search done - score: 56\n",
      "  [STOCHF] Grid search optimization...\n",
      "Completed 15/57: MACDEXT\n",
      "  [ROCR] Grid search done - score: 142\n",
      "  [SMA] Grid search optimization...\n",
      "Completed 16/57: ROCR\n",
      "  [CMO] Grid search done - score: 93\n",
      "  [EMA] Grid search optimization...\n",
      "Completed 17/57: CMO\n",
      "  [MFI] Grid search done - score: 91\n",
      "  [DEMA] Grid search optimization...\n",
      "Completed 18/57: MFI\n",
      "  [DEMA] Grid search done - score: 94\n",
      "  [TEMA] Grid search optimization...\n",
      "Completed 19/57: DEMA\n",
      "  [SMA] Grid search done - score: 57\n",
      "  [KAMA] Grid search optimization...\n",
      "Completed 20/57: SMA\n",
      "  [KAMA] Grid search done - score: 52\n",
      "  [WMA] Grid search optimization...\n",
      "Completed 21/57: KAMA\n",
      "  [TEMA] Grid search done - score: 125\n",
      "  [TRIMA] Grid search optimization...\n",
      "Completed 22/57: TEMA\n",
      "  [EMA] Grid search done - score: 26\n",
      "  [T3] Grid search optimization...\n",
      "Completed 23/57: EMA\n",
      "  [WMA] Grid search done - score: 77\n",
      "  [SAR] Grid search optimization...\n",
      "Completed 24/57: WMA\n",
      "  [SAR] Grid search done - score: 41\n",
      "  [BBANDS] Grid search optimization...\n",
      "Completed 25/57: SAR\n",
      "  [TRIMA] Grid search done - score: 67\n",
      "  [HT_TRENDLINE] Grid search optimization...\n",
      "Completed 26/57: TRIMA\n",
      "  [HT_TRENDLINE] Grid search done - score: 0\n",
      "  [MA] Grid search optimization...\n",
      "Completed 27/57: HT_TRENDLINE\n",
      "  [T3] Grid search done - score: 108\n",
      "  [MAMA] Grid search optimization...\n",
      "Completed 28/57: T3\n",
      "  [MAMA] Grid search done - score: 23\n",
      "  [MIDPOINT] Grid search optimization...\n",
      "Completed 29/57: MAMA\n",
      "  [MIDPOINT] Grid search done - score: 70\n",
      "  [MIDPRICE] Grid search optimization...\n",
      "Completed 30/57: MIDPOINT\n",
      "  [MIDPRICE] Grid search done - score: 62\n",
      "  [SAREXT] Grid search optimization...\n",
      "Completed 31/57: MIDPRICE\n",
      "  [SAREXT] Grid search done - score: 0\n",
      "  [OBV] Grid search optimization...\n",
      "Completed 32/57: SAREXT\n",
      "  [OBV] Grid search done - score: 59\n",
      "  [AD] Grid search optimization...\n",
      "Completed 33/57: OBV\n",
      "  [AD] Grid search done - score: 66\n",
      "  [ADOSC] Grid search optimization...\n",
      "Completed 34/57: AD\n",
      "  [ADOSC] Grid search done - score: 47\n",
      "  [ATR] Grid search optimization...\n",
      "Completed 35/57: ADOSC\n",
      "  [MA] Grid search done - score: 125\n",
      "  [NATR] Grid search optimization...\n",
      "Completed 36/57: MA\n",
      "  [RSI] Grid search done - score: 136\n",
      "  [TRANGE] Grid search optimization...\n",
      "Completed 37/57: RSI\n",
      "  [TRANGE] Grid search done - score: 137\n",
      "  [HT_DCPERIOD] Grid search optimization...\n",
      "Completed 38/57: TRANGE\n",
      "  [ATR] Grid search done - score: 58\n",
      "  [HT_DCPHASE] Grid search optimization...\n",
      "Completed 39/57: ATR\n",
      "  [BBANDS] Grid search done - score: 166\n",
      "  [HT_PHASOR] Grid search optimization...\n",
      "Completed 40/57: BBANDS\n",
      "  [HT_PHASOR] Grid search done - score: 0\n",
      "  [HT_SINE] Grid search optimization...\n",
      "Completed 41/57: HT_PHASOR\n",
      "  [HT_SINE] Grid search done - score: 0\n",
      "  [HT_TRENDMODE] Grid search optimization...\n",
      "Completed 42/57: HT_SINE\n",
      "  [HT_TRENDMODE] Grid search done - score: 0\n",
      "Completed 43/57: HT_TRENDMODE\n",
      "  [STOCH] Grid search done - score: 114\n",
      "Completed 44/57: STOCH\n",
      "  [CCI] Grid search done - score: 124\n",
      "Completed 45/57: CCI\n",
      "  [NATR] Grid search done - score: 81\n",
      "Completed 46/57: NATR\n",
      "  [WILLR] Grid search done - score: 114\n",
      "Completed 47/57: WILLR\n",
      "  [ROCR100] Grid search done - score: 93\n",
      "Completed 48/57: ROCR100\n",
      "  [PLUS_DI] Grid search done - score: 137\n",
      "Completed 49/57: PLUS_DI\n",
      "  [ADXR] Grid search done - score: 104\n",
      "Completed 50/57: ADXR\n",
      "  [ADX] Grid search done - score: 109\n",
      "Completed 51/57: ADX\n",
      "  [STOCHF] Grid search done - score: 121\n",
      "Completed 52/57: STOCHF\n",
      "  [DX] Grid search done - score: 129\n",
      "Completed 53/57: DX\n",
      "  [STOCHRSI] Grid search done - score: 140\n",
      "Completed 54/57: STOCHRSI\n",
      "  [HT_DCPHASE] Grid search done - score: 99\n",
      "Completed 55/57: HT_DCPHASE\n",
      "  [HT_DCPERIOD] Grid search done - score: 141\n",
      "Completed 56/57: HT_DCPERIOD\n",
      "  [MINUS_DI] Grid search done - score: 162\n",
      "Completed 57/57: MINUS_DI\n",
      "\n",
      "Dataset built with 124 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:384: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_entry\"] = result.gs_entry\n",
      "c:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\indicator_optimizer\\dataset_builder.py:385: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{ind_name}_gs_exit\"] = result.gs_exit\n"
     ]
    }
   ],
   "source": [
    "# 1. Build dataset\n",
    "builder = DatasetBuilder(data_dir=data_dir, period_hours=4, n_workers=15, signal_shift=0)\n",
    "df = builder.build('DOGE', \n",
    "                   threshold_pct=1.5,\n",
    "                   hyperopt=False,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1cb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"doge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9864e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"doge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Preprocess\n",
    "# preprocessor = DataPreprocessor(target_shift=4)\n",
    "# features, targets = preprocessor.fit_transform(df)\n",
    "\n",
    "# # 3. Create sequences\n",
    "# feat_seqs, tgt_seqs = create_sequences(features, targets, input_seq_length=12, output_seq_length=4)\n",
    "\n",
    "# 4. Validate and filter\n",
    "# validator = SequenceValidator()\n",
    "# feat_seqs, tgt_seqs, seq_types = validator.filter_valid_sequences(feat_seqs, tgt_seqs)\n",
    "\n",
    "# # 5. Create dataset\n",
    "# dataset = SignalDataset(feat_seqs, tgt_seqs, seq_types)\n",
    "\n",
    "# # 6. Train\n",
    "# config = TrainingConfig(\n",
    "#     epochs=100,\n",
    "#     auto_class_weights=True,\n",
    "#     class_weight_power=1.5,     # Even stronger (was 1.0)\n",
    "#     focal_loss=True,\n",
    "#     focal_gamma=4.0,            # More aggressive (was 3.0)\n",
    "#     label_smoothing=0.15,\n",
    "#     dropout=0.5,\n",
    "#     weight_decay=0.01,          # Stronger L2\n",
    "#     hidden_size=64,             # Smaller model in ModelConfig\n",
    "#     patience=10,\n",
    "#     checkpoint_dir='checkpoints/'\n",
    "# )\n",
    "\n",
    "# # Also use smaller model\n",
    "# model_config = ModelConfig(input_size=preprocessor.get_num_features(), hidden_size=64, num_layers=1)\n",
    "\n",
    "\n",
    "# model = LSTMSignalPredictor(model_config)\n",
    "# trainer = Trainer(model, config, preprocessor=preprocessor)\n",
    "# history = trainer.train(dataset)\n",
    "\n",
    "\n",
    "# # Or evaluate silently and print later\n",
    "# metrics = trainer.evaluate_all()\n",
    "# trainer.print_evaluation_report(metrics)\n",
    "\n",
    "# from crypto_analysis import Predictor\n",
    "\n",
    "# # Load your trained model\n",
    "# predictor = Predictor.from_checkpoint(\n",
    "#     'checkpoints/best_model.pt',\n",
    "#     'checkpoints/preprocessor.pkl'\n",
    "# )\n",
    "\n",
    "# # Find optimal threshold on validation data\n",
    "# threshold_results = predictor.find_optimal_threshold(\n",
    "#     df=df.tail(int(df.shape[0]*0.2)),\n",
    "#     thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#     metric='f1',  # or 'precision', 'recall'\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# print(f\"Best threshold: {threshold_results['best_threshold']}\")\n",
    "\n",
    "# # Evaluate performance with thresholded predictions\n",
    "# metrics = predictor.evaluate_with_threshold(\n",
    "#     df.tail(int(df.shape[0]*0.2)),\n",
    "#     entry_threshold=0.7,\n",
    "#     exit_threshold=0.8\n",
    "# )\n",
    "\n",
    "# print(f\"Entry Precision: {metrics['entry_precision']:.4f}\")\n",
    "# print(f\"Entry Recall: {metrics['entry_recall']:.4f}\")\n",
    "# print(f\"Entry F1: {metrics['entry_f1']:.4f}\")\n",
    "\n",
    "# print(f\"Exit Precision: {metrics['exit_precision']:.4f}\")\n",
    "# print(f\"Exit Recall: {metrics['exit_recall']:.4f}\")\n",
    "# print(f\"Exit F1: {metrics['exit_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c761614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMMetaheuristicOptimizer (APO) initialized:\n",
      "  - DataFrame mode: binary\n",
      "  - Feature columns: 119\n",
      "  - Hyperparameters: 11\n",
      "  - Total dimension: 130\n",
      "  - Population size: 12\n",
      "  - Iterations: 70\n",
      "  - Workers: 15\n",
      "  - APO np_neighbors: 2\n",
      "  - APO pf_max: 0.18\n",
      "  - Elitist selection: True\n",
      "  - Elitist constant: 0.28\n",
      "  - Correlation vector: min=0.0000, max=0.1226, mean=0.0224\n",
      "\n",
      "============================================================\n",
      "Starting APO Metaheuristic Optimization\n",
      "Run ID: a2dc93ba\n",
      "============================================================\n",
      "\n",
      "Evaluating initial population...\n",
      "iter:-1 indv:2 fitness:0.2818 features:56\n",
      "iter:-1 indv:11 fitness:0.4102 features:66\n",
      "iter:-1 indv:5 fitness:0.3538 features:59\n",
      "iter:-1 indv:9 fitness:0.4032 features:58\n",
      "iter:-1 indv:7 fitness:0.1678 features:62\n",
      "iter:-1 indv:0 fitness:0.3897 features:52\n",
      "iter:-1 indv:8 fitness:0.3361 features:61\n",
      "iter:-1 indv:10 fitness:0.3772 features:63\n",
      "iter:-1 indv:6 fitness:0.3735 features:59\n",
      "iter:-1 indv:3 fitness:0.4024 features:51\n",
      "iter:-1 indv:4 fitness:0.3790 features:62\n",
      "iter:-1 indv:1 fitness:0.3469 features:57\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "INIT - Best Individual Per-Class Metrics (fitness: 0.410226)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9462       0.9042       0.9247       428       \n",
      "trade      0.3492       0.5000       0.4112       44        \n",
      "\n",
      "--- Iteration 1/70 ---\n",
      "Current best fitness: 0.4102\n",
      "Evaluating new candidates...\n",
      "iter:0 indv:0 fitness:0.3661 features:66\n",
      "iter:0 indv:9 fitness:0.2857 features:52\n",
      "iter:0 indv:7 fitness:0.0000 features:61\n",
      "iter:0 indv:2 fitness:0.4205 features:63\n",
      "iter:0 indv:10 fitness:0.0428 features:66\n",
      "iter:0 indv:4 fitness:0.3629 features:60\n",
      "iter:0 indv:11 fitness:0.0700 features:55\n",
      "iter:0 indv:6 fitness:0.3925 features:58\n",
      "iter:0 indv:5 fitness:0.4426 features:59\n",
      "iter:0 indv:3 fitness:0.3178 features:57\n",
      "iter:0 indv:1 fitness:0.4245 features:55\n",
      "iter:0 indv:8 fitness:0.3361 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 0 - Best Individual Per-Class Metrics (fitness: 0.442598)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9558       0.8598       0.9053       428       \n",
      "trade      0.3103       0.6136       0.4122       44        \n",
      "\n",
      "--- Iteration 2/70 ---\n",
      "Current best fitness: 0.4426\n",
      "Evaluating new candidates...\n",
      "iter:1 indv:9 fitness:0.0000 features:51\n",
      "iter:1 indv:7 fitness:0.1791 features:61\n",
      "iter:1 indv:5 fitness:0.3080 features:66\n",
      "iter:1 indv:2 fitness:0.3483 features:59\n",
      "iter:1 indv:10 fitness:0.4048 features:52\n",
      "iter:1 indv:0 fitness:0.3336 features:56\n",
      "iter:1 indv:3 fitness:0.3633 features:68\n",
      "iter:1 indv:6 fitness:0.3369 features:58\n",
      "iter:1 indv:4 fitness:0.3613 features:55\n",
      "iter:1 indv:11 fitness:0.1091 features:54\n",
      "iter:1 indv:8 fitness:0.0745 features:67\n",
      "iter:1 indv:1 fitness:0.3670 features:55\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 1 - Best Individual Per-Class Metrics (fitness: 0.442598)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9558       0.8598       0.9053       428       \n",
      "trade      0.3103       0.6136       0.4122       44        \n",
      "\n",
      "--- Iteration 3/70 ---\n",
      "Current best fitness: 0.4426\n",
      "Evaluating new candidates...\n",
      "iter:2 indv:5 fitness:0.3996 features:64\n",
      "iter:2 indv:9 fitness:0.1115 features:58\n",
      "iter:2 indv:11 fitness:0.3747 features:62\n",
      "iter:2 indv:1 fitness:0.4394 features:57\n",
      "iter:2 indv:10 fitness:0.1232 features:53\n",
      "iter:2 indv:0 fitness:0.3557 features:57\n",
      "iter:2 indv:4 fitness:0.3389 features:59\n",
      "iter:2 indv:6 fitness:0.4078 features:50\n",
      "iter:2 indv:2 fitness:0.3414 features:58\n",
      "iter:2 indv:3 fitness:0.3164 features:68\n",
      "iter:2 indv:8 fitness:0.4343 features:67\n",
      "iter:2 indv:7 fitness:0.3865 features:64\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 2 - Best Individual Per-Class Metrics (fitness: 0.442598)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9558       0.8598       0.9053       428       \n",
      "trade      0.3103       0.6136       0.4122       44        \n",
      "\n",
      "--- Iteration 4/70 ---\n",
      "Current best fitness: 0.4426\n",
      "Evaluating new candidates...\n",
      "iter:3 indv:4 fitness:0.4548 features:61\n",
      "iter:3 indv:5 fitness:0.3719 features:61\n",
      "iter:3 indv:7 fitness:0.3868 features:63\n",
      "iter:3 indv:0 fitness:0.4450 features:57\n",
      "iter:3 indv:6 fitness:0.3515 features:57\n",
      "iter:3 indv:1 fitness:0.3977 features:57\n",
      "iter:3 indv:2 fitness:0.0000 features:68\n",
      "iter:3 indv:11 fitness:0.3841 features:63\n",
      "iter:3 indv:9 fitness:0.2698 features:56\n",
      "iter:3 indv:8 fitness:0.3995 features:67\n",
      "iter:3 indv:3 fitness:0.0022 features:65\n",
      "iter:3 indv:10 fitness:0.3503 features:54\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 3 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "\n",
      "--- Iteration 5/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:4 indv:0 fitness:0.3461 features:64\n",
      "iter:4 indv:7 fitness:0.0892 features:61\n",
      "iter:4 indv:10 fitness:0.3099 features:48\n",
      "iter:4 indv:1 fitness:0.4188 features:59\n",
      "iter:4 indv:5 fitness:0.3261 features:66\n",
      "iter:4 indv:9 fitness:0.3235 features:66\n",
      "iter:4 indv:2 fitness:0.3783 features:61\n",
      "iter:4 indv:8 fitness:0.3978 features:67\n",
      "iter:4 indv:4 fitness:0.3922 features:63\n",
      "iter:4 indv:3 fitness:0.4320 features:72\n",
      "iter:4 indv:6 fitness:0.0025 features:53\n",
      "iter:4 indv:11 fitness:0.2884 features:52\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 4 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "Checkpoint saved to lstm_optimization_checkpoints\\checkpoint_iter_5.pkl\n",
      "\n",
      "--- Iteration 6/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:5 indv:7 fitness:0.3685 features:61\n",
      "iter:5 indv:0 fitness:0.3666 features:64\n",
      "iter:5 indv:9 fitness:0.3421 features:66\n",
      "iter:5 indv:10 fitness:0.3441 features:48\n",
      "iter:5 indv:2 fitness:0.0000 features:61\n",
      "iter:5 indv:5 fitness:0.0670 features:66\n",
      "iter:5 indv:1 fitness:0.4082 features:59\n",
      "iter:5 indv:6 fitness:0.0000 features:53\n",
      "iter:5 indv:4 fitness:0.4142 features:63\n",
      "iter:5 indv:8 fitness:0.0402 features:67\n",
      "iter:5 indv:3 fitness:0.3596 features:72\n",
      "iter:5 indv:11 fitness:0.0928 features:52\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 5 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "\n",
      "--- Iteration 7/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:6 indv:0 fitness:0.3467 features:64\n",
      "iter:6 indv:7 fitness:0.3854 features:61\n",
      "iter:6 indv:10 fitness:0.3447 features:48\n",
      "iter:6 indv:11 fitness:0.0000 features:52\n",
      "iter:6 indv:4 fitness:0.3710 features:63\n",
      "iter:6 indv:6 fitness:0.0000 features:53\n",
      "iter:6 indv:5 fitness:0.0000 features:66\n",
      "iter:6 indv:1 fitness:0.3995 features:59\n",
      "iter:6 indv:2 fitness:0.3946 features:61\n",
      "iter:6 indv:8 fitness:0.1544 features:67\n",
      "iter:6 indv:9 fitness:0.3560 features:65\n",
      "iter:6 indv:3 fitness:0.4108 features:72\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 6 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "\n",
      "--- Iteration 8/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:7 indv:0 fitness:0.0179 features:64\n",
      "iter:7 indv:7 fitness:0.4290 features:61\n",
      "iter:7 indv:10 fitness:0.2773 features:48\n",
      "iter:7 indv:9 fitness:0.3014 features:65\n",
      "iter:7 indv:4 fitness:0.3988 features:63\n",
      "iter:7 indv:2 fitness:0.3053 features:61\n",
      "iter:7 indv:11 fitness:0.0000 features:52\n",
      "iter:7 indv:6 fitness:0.2765 features:52\n",
      "iter:7 indv:5 fitness:0.0000 features:66\n",
      "iter:7 indv:1 fitness:0.3734 features:59\n",
      "iter:7 indv:3 fitness:0.3966 features:72\n",
      "iter:7 indv:8 fitness:0.4076 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 7 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "\n",
      "--- Iteration 9/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:8 indv:0 fitness:0.3369 features:63\n",
      "iter:8 indv:4 fitness:0.3882 features:62\n",
      "iter:8 indv:9 fitness:0.4250 features:69\n",
      "iter:8 indv:10 fitness:0.2123 features:66\n",
      "iter:8 indv:5 fitness:0.3263 features:63\n",
      "iter:8 indv:6 fitness:0.3381 features:52\n",
      "iter:8 indv:2 fitness:0.0342 features:63\n",
      "iter:8 indv:7 fitness:0.4518 features:68\n",
      "iter:8 indv:1 fitness:0.3257 features:59\n",
      "iter:8 indv:11 fitness:0.0298 features:52\n",
      "iter:8 indv:3 fitness:0.3324 features:72\n",
      "iter:8 indv:8 fitness:0.1329 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 8 - Best Individual Per-Class Metrics (fitness: 0.454816)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9530       0.8995       0.9255       428       \n",
      "trade      0.3676       0.5682       0.4464       44        \n",
      "\n",
      "--- Iteration 10/70 ---\n",
      "Current best fitness: 0.4548\n",
      "Evaluating new candidates...\n",
      "iter:9 indv:0 fitness:0.3175 features:61\n",
      "iter:9 indv:11 fitness:0.3311 features:58\n",
      "iter:9 indv:5 fitness:0.3286 features:54\n",
      "iter:9 indv:2 fitness:0.4627 features:54\n",
      "iter:9 indv:6 fitness:0.3155 features:70\n",
      "iter:9 indv:9 fitness:0.3788 features:54\n",
      "iter:9 indv:10 fitness:0.3568 features:69\n",
      "iter:9 indv:1 fitness:0.3539 features:66\n",
      "iter:9 indv:3 fitness:0.4703 features:55\n",
      "iter:9 indv:7 fitness:0.3613 features:67\n",
      "iter:9 indv:4 fitness:0.2015 features:69\n",
      "iter:9 indv:8 fitness:0.3319 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 9 - Best Individual Per-Class Metrics (fitness: 0.470270)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9589       0.8715       0.9131       428       \n",
      "trade      0.3373       0.6364       0.4409       44        \n",
      "Checkpoint saved to lstm_optimization_checkpoints\\checkpoint_iter_10.pkl\n",
      "\n",
      "--- Iteration 11/70 ---\n",
      "Current best fitness: 0.4703\n",
      "Evaluating new candidates...\n",
      "iter:10 indv:10 fitness:0.4111 features:57\n",
      "iter:10 indv:5 fitness:0.2907 features:53\n",
      "iter:10 indv:1 fitness:0.4484 features:55\n",
      "iter:10 indv:11 fitness:0.4055 features:59\n",
      "iter:10 indv:9 fitness:0.4142 features:67\n",
      "iter:10 indv:2 fitness:0.3623 features:58\n",
      "iter:10 indv:0 fitness:0.4205 features:56\n",
      "iter:10 indv:6 fitness:0.3935 features:69\n",
      "iter:10 indv:3 fitness:0.1858 features:68\n",
      "iter:10 indv:4 fitness:0.3792 features:69\n",
      "iter:10 indv:7 fitness:0.3469 features:70\n",
      "iter:10 indv:8 fitness:0.3404 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 10 - Best Individual Per-Class Metrics (fitness: 0.470270)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9589       0.8715       0.9131       428       \n",
      "trade      0.3373       0.6364       0.4409       44        \n",
      "\n",
      "--- Iteration 12/70 ---\n",
      "Current best fitness: 0.4703\n",
      "Evaluating new candidates...\n",
      "iter:11 indv:2 fitness:0.4205 features:59\n",
      "iter:11 indv:10 fitness:0.4012 features:61\n",
      "iter:11 indv:9 fitness:0.0000 features:66\n",
      "iter:11 indv:5 fitness:0.1531 features:57\n",
      "iter:11 indv:0 fitness:0.3691 features:56\n",
      "iter:11 indv:6 fitness:0.3292 features:69\n",
      "iter:11 indv:11 fitness:0.0459 features:63\n",
      "iter:11 indv:1 fitness:0.3740 features:55\n",
      "iter:11 indv:3 fitness:0.3739 features:68\n",
      "iter:11 indv:4 fitness:0.3629 features:69\n",
      "iter:11 indv:7 fitness:0.3814 features:68\n",
      "iter:11 indv:8 fitness:0.1889 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 11 - Best Individual Per-Class Metrics (fitness: 0.470270)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9589       0.8715       0.9131       428       \n",
      "trade      0.3373       0.6364       0.4409       44        \n",
      "\n",
      "--- Iteration 13/70 ---\n",
      "Current best fitness: 0.4703\n",
      "Evaluating new candidates...\n",
      "iter:12 indv:11 fitness:0.3897 features:63\n",
      "iter:12 indv:9 fitness:0.0000 features:67\n",
      "iter:12 indv:5 fitness:0.0000 features:57\n",
      "iter:12 indv:0 fitness:0.3494 features:56\n",
      "iter:12 indv:2 fitness:0.3469 features:59\n",
      "iter:12 indv:10 fitness:0.4729 features:61\n",
      "iter:12 indv:1 fitness:0.3788 features:55\n",
      "iter:12 indv:6 fitness:0.3939 features:69\n",
      "iter:12 indv:7 fitness:0.3776 features:68\n",
      "iter:12 indv:3 fitness:0.3747 features:68\n",
      "iter:12 indv:4 fitness:0.3155 features:69\n",
      "iter:12 indv:8 fitness:0.2861 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 12 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "\n",
      "--- Iteration 14/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:13 indv:7 fitness:0.3868 features:66\n",
      "iter:13 indv:9 fitness:0.2497 features:55\n",
      "iter:13 indv:2 fitness:0.2981 features:59\n",
      "iter:13 indv:3 fitness:0.3591 features:61\n",
      "iter:13 indv:11 fitness:0.0000 features:68\n",
      "iter:13 indv:0 fitness:0.0000 features:62\n",
      "iter:13 indv:6 fitness:0.4132 features:60\n",
      "iter:13 indv:1 fitness:0.3615 features:55\n",
      "iter:13 indv:4 fitness:0.4043 features:68\n",
      "iter:13 indv:5 fitness:0.4099 features:63\n",
      "iter:13 indv:10 fitness:0.0023 features:53\n",
      "iter:13 indv:8 fitness:0.1069 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 13 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "\n",
      "--- Iteration 15/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:14 indv:9 fitness:0.0000 features:56\n",
      "iter:14 indv:3 fitness:0.2148 features:61\n",
      "iter:14 indv:6 fitness:0.4079 features:60\n",
      "iter:14 indv:0 fitness:0.0029 features:62\n",
      "iter:14 indv:2 fitness:0.4101 features:59\n",
      "iter:14 indv:11 fitness:0.0000 features:68\n",
      "iter:14 indv:7 fitness:0.3877 features:66\n",
      "iter:14 indv:1 fitness:0.3503 features:55\n",
      "iter:14 indv:10 fitness:0.0195 features:53\n",
      "iter:14 indv:5 fitness:0.3511 features:64\n",
      "iter:14 indv:4 fitness:0.4165 features:68\n",
      "iter:14 indv:8 fitness:0.4288 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 14 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "Checkpoint saved to lstm_optimization_checkpoints\\checkpoint_iter_15.pkl\n",
      "\n",
      "--- Iteration 16/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:15 indv:9 fitness:0.0000 features:56\n",
      "iter:15 indv:7 fitness:0.3807 features:65\n",
      "iter:15 indv:2 fitness:0.3978 features:59\n",
      "iter:15 indv:6 fitness:0.3954 features:61\n",
      "iter:15 indv:3 fitness:0.3096 features:61\n",
      "iter:15 indv:0 fitness:0.4198 features:62\n",
      "iter:15 indv:1 fitness:0.4014 features:55\n",
      "iter:15 indv:4 fitness:0.4372 features:68\n",
      "iter:15 indv:5 fitness:0.3682 features:64\n",
      "iter:15 indv:10 fitness:0.0000 features:53\n",
      "iter:15 indv:11 fitness:0.3498 features:75\n",
      "iter:15 indv:8 fitness:0.4253 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 15 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "\n",
      "--- Iteration 17/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:16 indv:9 fitness:0.3472 features:56\n",
      "iter:16 indv:7 fitness:0.3596 features:65\n",
      "iter:16 indv:6 fitness:0.2857 features:60\n",
      "iter:16 indv:3 fitness:0.2857 features:61\n",
      "iter:16 indv:1 fitness:0.4012 features:55\n",
      "iter:16 indv:5 fitness:0.3719 features:64\n",
      "iter:16 indv:0 fitness:0.4438 features:62\n",
      "iter:16 indv:4 fitness:0.4606 features:68\n",
      "iter:16 indv:2 fitness:0.3108 features:59\n",
      "iter:16 indv:10 fitness:0.4250 features:53\n",
      "iter:16 indv:11 fitness:0.0700 features:69\n",
      "iter:16 indv:8 fitness:0.2809 features:67\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 16 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "\n",
      "--- Iteration 18/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:17 indv:4 fitness:0.3749 features:60\n",
      "iter:17 indv:9 fitness:0.4066 features:57\n",
      "iter:17 indv:6 fitness:0.1369 features:65\n",
      "iter:17 indv:0 fitness:0.0000 features:62\n",
      "iter:17 indv:2 fitness:0.3896 features:53\n",
      "iter:17 indv:5 fitness:0.0058 features:67\n",
      "iter:17 indv:8 fitness:0.3873 features:60\n",
      "iter:17 indv:10 fitness:0.0000 features:64\n",
      "iter:17 indv:11 fitness:0.4184 features:63\n",
      "iter:17 indv:1 fitness:0.4043 features:55\n",
      "iter:17 indv:3 fitness:0.3071 features:67\n",
      "iter:17 indv:7 fitness:0.4169 features:57\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "ITER 17 - Best Individual Per-Class Metrics (fitness: 0.472861)\n",
      "------------------------------------------------------------------------\n",
      "Class      Precision    Recall       F1           Support   \n",
      "--------------------------------------------------------\n",
      "hold       0.9590       0.8738       0.9144       428       \n",
      "trade      0.3415       0.6364       0.4444       44        \n",
      "\n",
      "--- Iteration 19/70 ---\n",
      "Current best fitness: 0.4729\n",
      "Evaluating new candidates...\n",
      "iter:18 indv:9 fitness:0.2829 features:57\n",
      "iter:18 indv:6 fitness:0.3500 features:65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[32m      2\u001b[39m optimizer = LSTMMetaheuristicOptimizer(\n\u001b[32m      3\u001b[39m     df=df,\n\u001b[32m      4\u001b[39m     pop_size=\u001b[32m12\u001b[39m,              \u001b[38;5;66;03m# +2: Better exploration\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     enable_logging=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m result = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest fitness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.best_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelected features (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.n_features_selected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.selected_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\lstm_optimizer.py:1124\u001b[39m, in \u001b[36mLSTMMetaheuristicOptimizer.optimize\u001b[39m\u001b[34m(self, start_iteration)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating new candidates...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m new_fitness, new_cols, new_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_population_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_population\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43miter_num\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[38;5;66;03m# Greedy selection: replace only if new solution is better\u001b[39;00m\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ps):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\irisbridge\\Desktop\\projects\\freqtrade\\user_data\\crypto_analysis\\lstm_optimizer.py:736\u001b[39m, in \u001b[36mLSTMMetaheuristicOptimizer._evaluate_population_parallel\u001b[39m\u001b[34m(self, population, iteration)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=\u001b[38;5;28mself\u001b[39m.n_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    731\u001b[39m     futures = {\n\u001b[32m    732\u001b[39m         executor.submit(\u001b[38;5;28mself\u001b[39m._evaluate_individual, ind, idx): idx\n\u001b[32m    733\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(population)\n\u001b[32m    734\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Python\\pythoncore-3.13-64\\Lib\\concurrent\\futures\\_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Python\\pythoncore-3.13-64\\Lib\\threading.py:660\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    658\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Python\\pythoncore-3.13-64\\Lib\\threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "optimizer = LSTMMetaheuristicOptimizer(\n",
    "    df=df,\n",
    "    pop_size=12,              # +2: Better exploration\n",
    "    iterations=70,            # +20: Still improving, allow more time\n",
    "    n_workers=15,\n",
    "    np_neighbors=2,           # +1: Better neighborhood effect\n",
    "    pf_max=0.18,              # +0.03: More exploration (params diverse)\n",
    "    epochs_per_eval=100,\n",
    "    checkpoint_interval=5,\n",
    "    elitist_selection=True,\n",
    "    elitist_constant=0.28,    # -0.02: Slightly more exploration\n",
    "    verbose=True,\n",
    "    enable_logging=True,\n",
    ")\n",
    "\n",
    "result = optimizer.optimize()\n",
    "\n",
    "print(f\"Best fitness: {result.best_fitness}\")\n",
    "print(f\"Selected features ({result.n_features_selected}): {result.selected_features}\")\n",
    "print(f\"Best params: {result.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = optimizer.train_from_result(result, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load your trained model\n",
    "# predictor = Predictor.from_checkpoint(\n",
    "#     'checkpoints/best_model.pt',\n",
    "#     'checkpoints/preprocessor.pkl'\n",
    "# )\n",
    "\n",
    "# # Find optimal threshold on validation data\n",
    "# threshold_results = predictor.find_optimal_threshold(\n",
    "#     df=df.tail(int(df.shape[0]*0.2)),\n",
    "#     thresholds=[0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#     metric='f1',  # or 'precision', 'recall'\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# print(f\"Best threshold: {threshold_results['best_threshold']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate performance with thresholded predictions\n",
    "# metrics = predictor.evaluate_with_threshold(\n",
    "#     df.tail(int(df.shape[0]*0.2)),\n",
    "#     entry_threshold=0.3,\n",
    "#     exit_threshold=0.3\n",
    "# )\n",
    "\n",
    "# print(f\"Entry Precision: {metrics['entry_precision']:.4f}\")\n",
    "# print(f\"Entry Recall: {metrics['entry_recall']:.4f}\")\n",
    "# print(f\"Entry F1: {metrics['entry_f1']:.4f}\")\n",
    "\n",
    "# print(f\"Exit Precision: {metrics['exit_precision']:.4f}\")\n",
    "# print(f\"Exit Recall: {metrics['exit_recall']:.4f}\")\n",
    "# print(f\"Exit F1: {metrics['exit_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.predict_with_threshold(df.tail(int(df.shape[0]*0.2)), 0.9, 0.9).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crypto_analysis.signal_population import SignalPopulator\n",
    "\n",
    "# Test with DOGE and period_hours=4\n",
    "populator = SignalPopulator(data_dir=data_dir, period_hours=4)\n",
    "df_signals = populator.populate_signals(\"DOGE\", threshold_pct=1.5)\n",
    "\n",
    "print(f\"\\nDataFrame shape: {df_signals.shape}\")\n",
    "print(f\"Entry signals: {(df_signals['signal'] == 'entry').sum()}\")\n",
    "print(f\"Exit signals: {(df_signals['signal'] == 'exit').sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
